{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7576fa45",
   "metadata": {},
   "source": [
    "## Session Overview\n",
    "\n",
    "In this session, we will:\n",
    "\n",
    "- Run Ollama locally and explore its capabilities.\n",
    "- Install the `llama3:2` (latest) model.\n",
    "- Compare the outputs of three language models: **GPT**, **Gemini**, and **Llama**.\n",
    "- Use GPT as a judge to evaluate the outputs (LLM-as-judge approach).\n",
    "- Explore generating structured outputs using **Pydantic**.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Install Ollama**: Follow the instructions at [Ollama's official website](https://ollama.com/download) to install Ollama on your machine.\n",
    "- **Download the Llama 3 model**: Run the following command in your terminal to download and start the Llama 3 model:\n",
    "  \n",
    "  ```\n",
    "  ollama run llama3.2:1b\n",
    "  ```\n",
    "\n",
    "  This will ensure the model is available locally for comparison.\n",
    "- **Gemini API Key (Optional)**: Sign-up on Gemini for a free account, create an API key and store it in your .env file as `GOOGLE_API_KEY`. See `.env.example` for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63572077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and initiate clients for OpenAI, Gemini and Ollama (llama)\n",
    "\n",
    "# Gemini Base URL: https://generativelanguage.googleapis.com/v1beta/openai/\n",
    "# Gemini Model: gemini-2.0-flash\n",
    "# Gemini Models: https://ai.google.dev/gemini-api/docs/models\n",
    "\n",
    "# Ollama Base URL: http://localhost:11434/v1\n",
    "# Ollama Model: llama3.2\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask GPT to generate a nuanced question that can be asked to GPT, Gemini and Ollama to judge their capabilities\n",
    "# Prompt: Please come up with a challenging, nuanced question that can be asked to an LLM to evaluate its intelligence. Answer only with a question, no explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b339cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare messages for LLMs with question to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask GPT to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ca57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Gemini to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Ollama to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71321c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prompt to ask GPT 4.1 to judge the answers based on clarity and strength of the argument.\n",
    "# GPT should respond with a json object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send judge prompt to GPT 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse judge output to json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456aacc4",
   "metadata": {},
   "source": [
    "### Is there a better way to obtain structured output?\n",
    "\n",
    "Yes, you can use **Pydantic** to define a schema for the expected output and validate the response, ensuring it adheres to the desired structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74432c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pydantic schema for judge's structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23da4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the judge prompt. This time, without the json object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c721b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send judge prompt to GPT 4.1 again\n",
    "# Instead of Chat Completions create, use parse this time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
