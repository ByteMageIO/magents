{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1fe34f",
   "metadata": {},
   "source": [
    "## RAG & Tools 101\n",
    "\n",
    "\n",
    "## Session Overview\n",
    "\n",
    "- Introduction to Retrieval-Augmented Generation (RAG) and practical tools.\n",
    "- Step-by-step guide to building a personal RAG agent using your LinkedIn profile and a summary.\n",
    "- Overview of integrating tools such as email notifications for unanswered questions and contact collection.\n",
    "- Instructions for setting up prerequisites and dependencies.\n",
    "\n",
    "\n",
    "### RAG (Retrieval-Augmented Generation) Steps\n",
    "\n",
    "1. **Download your LinkedIn Profile as PDF**\n",
    "\n",
    "   - Go to your LinkedIn profile, click on the \"More\" button, and select \"Save to PDF\".\n",
    "   - Example screenshot:\n",
    "\n",
    "#      <img src=\"./data/linkedin_pdf_download.png\" alt=\"How to download LinkedIn profile as PDF\" width=\"800\"/>\n",
    "\n",
    "2. **Write a Summary Text File**\n",
    "\n",
    "   - Use GPT to generate a professional summary about yourself.\n",
    "   - **Prompt:**  \n",
    "     ```\n",
    "     Write down a detailed page on everything you know about me as a professional. Write it as if I am telling about myself. Output it as markdown so I can copy and paste it.\n",
    "     ```\n",
    "\n",
    "3. **Build an Agent to Answer Questions About You**\n",
    "\n",
    "   - Create an agent that can answer questions based on your LinkedIn PDF and summary.\n",
    "\n",
    "4. **Build a Chat Interface Using Gradio**\n",
    "\n",
    "   - Implement a chat UI with Gradio.\n",
    "   - Ensure the LLM has access to the conversation history for context.\n",
    "\n",
    "---\n",
    "\n",
    "### Tools\n",
    "\n",
    "- **Email Tool for Unanswered Questions:**  \n",
    "  Add a tool to send an email whenever the LLM cannot answer a user's question.\n",
    "\n",
    "- **Email Tool for Contact Details:**  \n",
    "  Add a tool to send an email if the user provides their contact details (name and email).\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Resend API key\n",
    "- LinkedIn Profile PDF\n",
    "- Install dependencies:\n",
    "  ```\n",
    "  uv add pypdf resend gradio\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import resend\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables, initiate client for OpenAI and set Resend API key\n",
    "load_dotenv(override=True)\n",
    "openai_client = OpenAI()\n",
    "resend.api_key = os.getenv(\"RESEND_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sending email through Resend\n",
    "\n",
    "def send_email(subject: str, html_body: str):\n",
    "    params: resend.Emails.SendParams = {\n",
    "        \"from\": \"onboarding@resend.dev\",\n",
    "        \"to\": \"YOUR_EMAIL_ADDRESS_HERE@gmail.com\",\n",
    "        \"subject\": subject,\n",
    "        \"html\": html_body,\n",
    "    }\n",
    "    resend.Emails.send(params)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read summary file\n",
    "with open(\"./data/summary.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read linkedin profile pdf\n",
    "reader = PdfReader(\"./data/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prompt providing information about you.\n",
    "# Ask it to act as you and answer questions related to your career, background, skills and experience.\n",
    "# Use the summary and linkedin profile to answer questions.\n",
    "# If the LLM cannot answer a question, it should simply say so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user query and answer it using the system prompt and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ca783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Console is too boring. Let's build a chat interface using Gradio.\n",
    "# Define gradio chat function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75711240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch gradio chat interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47b458",
   "metadata": {},
   "source": [
    "# Tools Overview\n",
    "\n",
    "In modern AI applications, **tools** (also known as function calls or plugins) enable language models to interact with external systems, retrieve information, or perform actions beyond their native capabilities. By defining and integrating tools, you can extend the model’s usefulness—allowing it to answer questions it otherwise couldn’t, automate workflows, or record important data.\n",
    "\n",
    "The typical flow involves:\n",
    "1. The user asks a question or makes a request.\n",
    "2. The language model determines if it needs to call a tool to fulfill the request.\n",
    "3. If so, it calls the appropriate tool, passing the necessary parameters.\n",
    "4. The tool executes, returns results, and the model incorporates those results into its response.\n",
    "\n",
    "Below is a diagram illustrating how tool calls flow between the user, the language model, and external functions:\n",
    "#      <img src=\"./data/function-calling-diagram-steps.png\" alt=\"Function calling diagram steps\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for recording unknown questions and user details.\n",
    "# Each tool definition is a dictionary with the following keys:\n",
    "# - type: \"function\"\n",
    "# - function: a dictionary with the following keys:\n",
    "#   - name: the name of the tool\n",
    "#   - description: a description of the tool\n",
    "#   - parameters: a dictionary with the following keys:\n",
    "#     - type: \"object\"\n",
    "#     - properties: a dictionary with the following keys:\n",
    "#       - question: a dictionary with the following keys:\n",
    "#         - type: \"string\"\n",
    "#         - description: \"The question that the user asked\"\n",
    "#     - required: a list of the required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ec0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to run the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12721acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the prompt and ask LLM to use tools this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a436c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the answer_query function to handle tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gradio chat function again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch chat interface"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
