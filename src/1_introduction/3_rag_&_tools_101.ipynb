{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1fe34f",
   "metadata": {},
   "source": [
    "## RAG & Tools 101\n",
    "\n",
    "\n",
    "## Session Overview\n",
    "\n",
    "- Introduction to Retrieval-Augmented Generation (RAG) and practical tools.\n",
    "- Step-by-step guide to building a personal RAG agent using your LinkedIn profile and a summary.\n",
    "- Overview of integrating tools such as email notifications for unanswered questions and contact collection.\n",
    "- Instructions for setting up prerequisites and dependencies.\n",
    "\n",
    "\n",
    "### RAG (Retrieval-Augmented Generation) Steps\n",
    "\n",
    "1. **Download your LinkedIn Profile as PDF**\n",
    "\n",
    "   - Go to your LinkedIn profile, click on the \"More\" button, and select \"Save to PDF\".\n",
    "   - Example screenshot:\n",
    "\n",
    "#      <img src=\"./data/linkedin_pdf_download.png\" alt=\"How to download LinkedIn profile as PDF\" width=\"800\"/>\n",
    "\n",
    "2. **Write a Summary Text File**\n",
    "\n",
    "   - Use GPT to generate a professional summary about yourself.\n",
    "   - **Prompt:**  \n",
    "     ```\n",
    "     Write down a detailed page on everything you know about me as a professional. Write it as if I am telling about myself. Output it as markdown so I can copy and paste it.\n",
    "     ```\n",
    "\n",
    "3. **Build an Agent to Answer Questions About You**\n",
    "\n",
    "   - Create an agent that can answer questions based on your LinkedIn PDF and summary.\n",
    "\n",
    "4. **Build a Chat Interface Using Gradio**\n",
    "\n",
    "   - Implement a chat UI with Gradio.\n",
    "   - Ensure the LLM has access to the conversation history for context.\n",
    "\n",
    "---\n",
    "\n",
    "### Tools\n",
    "\n",
    "- **Email Tool for Unanswered Questions:**  \n",
    "  Add a tool to send an email whenever the LLM cannot answer a user's question.\n",
    "\n",
    "- **Email Tool for Contact Details:**  \n",
    "  Add a tool to send an email if the user provides their contact details (name and email).\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Resend API key\n",
    "- LinkedIn Profile PDF\n",
    "- Install dependencies:\n",
    "  ```\n",
    "  uv add pypdf resend gradio\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import resend\n",
    "import gradio as gr\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables, initiate client for OpenAI and set Resend API key\n",
    "load_dotenv(override=True)\n",
    "openai_client = OpenAI()\n",
    "resend.api_key = os.getenv(\"RESEND_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sending email through Resend\n",
    "\n",
    "def send_email(subject: str, html_body: str):\n",
    "    params: resend.Emails.SendParams = {\n",
    "        \"from\": \"onboarding@resend.dev\",\n",
    "        \"to\": \"YOUR_EMAIL_ADDRESS_HERE@gmail.com\",\n",
    "        \"subject\": subject,\n",
    "        \"html\": html_body,\n",
    "    }\n",
    "    resend.Emails.send(params)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read summary file\n",
    "with open(\"./data/summary.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read linkedin profile pdf\n",
    "reader = PdfReader(\"./data/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prompt providing information about you.\n",
    "# Ask it to act as you and answer questions related to your career, background, skills and experience.\n",
    "# Use the summary and linkedin profile to answer questions.\n",
    "# If the LLM cannot answer a question, it should simply say so.\n",
    "name = \"YOUR NAME HERE\"\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are acting as {name}. You are answering questions on {name}'s website.\n",
    "You should answer questions related to {name}'s career, background, skills and experience.\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible.\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions.\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website.\n",
    "If you don't know the answer, say so.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "LinkedIn Profile:\n",
    "{linkedin}\n",
    "\"\"\"\n",
    "system_message = {\"role\": \"system\", \"content\": system_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user query and answer it using the system prompt and LLM\n",
    "\n",
    "def answer_query(user_queries):\n",
    "    messages = [system_message] + user_queries\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"What would you like to know about me?\")\n",
    "    if user_query == \"exit\":\n",
    "        break\n",
    "    answer = answer_query(user_query)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ca783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Console is too boring. Let's build a chat interface using Gradio.\n",
    "# Define gradio chat function first.\n",
    "\n",
    "def chat(message, history):\n",
    "    answer = answer_query(history + [{\"role\": \"user\", \"content\": message}])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75711240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch gradio chat interface\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for recording unknown questions and user details.\n",
    "# Each tool definition is a dictionary with the following keys:\n",
    "# - type: \"function\"\n",
    "# - function: a dictionary with the following keys:\n",
    "#   - name: the name of the tool\n",
    "#   - description: a description of the tool\n",
    "#   - parameters: a dictionary with the following keys:\n",
    "#     - type: \"object\"\n",
    "#     - properties: a dictionary with the following keys:\n",
    "#       - question: a dictionary with the following keys:\n",
    "#         - type: \"string\"\n",
    "#         - description: \"The question that the user asked\"\n",
    "#     - required: a list of the required parameters\n",
    "\n",
    "record_unknown_question_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"record_unknown_question\",\n",
    "        \"description\": \"Tool for recording an unknown question for future reference\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The question that the user asked\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"question\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "record_user_details_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"record_user_details\",\n",
    "        \"description\": \"Tool for recording user details\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the user\"\n",
    "                },\n",
    "                \"email\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email of the user\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"name\", \"email\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [record_unknown_question_tool, record_user_details_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ec0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to run the tools\n",
    "\n",
    "def record_unknown_question(question: str):\n",
    "    return send_email(subject=\"Unknown Question\", html_body=question)\n",
    "\n",
    "def record_user_details(name: str, email: str):\n",
    "    return send_email(subject=\"New User Details\", html_body=f\"Name: {name}, Email: {email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12721acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the prompt and ask LLM to use tools this time.\n",
    "\n",
    "name = \"Murtaza Khan\"\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are acting as {name}. You are answering questions on {name}'s website.\n",
    "You should answer questions related to {name}'s career, background, skills and experience.\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible.\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions.\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website.\n",
    "If you don't know the answer to any question, use record_unknown_question tool to record the question that you couldn't answer even if it is something trivial or not related to career.\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their name and email and record it using record_user_details tool.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "LinkedIn Profile:\n",
    "{linkedin}\n",
    "\"\"\"\n",
    "system_message = {\"role\": \"system\", \"content\": system_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a436c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the answer_query function to handle tool calls\n",
    "\n",
    "def answer_query(user_queries):\n",
    "    messages = [system_message] + user_queries\n",
    "    cycle_complete = False\n",
    "\n",
    "    while not cycle_complete:\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        \n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        \n",
    "        if finish_reason == \"tool_calls\":\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            tools_messages = []\n",
    "            for tool_call in tool_calls:\n",
    "                if tool_call.function.name == \"record_unknown_question\":\n",
    "                    question = json.loads(tool_call.function.arguments)[\"question\"]\n",
    "                    result = record_unknown_question(question)\n",
    "                    tools_messages.append({\"role\": \"tool\", \"content\": json.dumps(result), \"tool_call_id\": tool_call.id})\n",
    "                elif tool_call.function.name == \"record_user_details\":\n",
    "                    details = json.loads(tool_call.function.arguments)\n",
    "                    result = record_user_details(details[\"name\"], details[\"email\"])\n",
    "                    tools_messages.append({\"role\": \"tool\", \"content\": json.dumps(result), \"tool_call_id\": tool_call.id})\n",
    "            messages.append(response.choices[0].message)\n",
    "            messages.extend(tools_messages)\n",
    "        else:\n",
    "            cycle_complete = True\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gradio chat function again\n",
    "\n",
    "def chat(message, history):\n",
    "    answer = answer_query(history + [{\"role\": \"user\", \"content\": message}])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch chat interface\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
