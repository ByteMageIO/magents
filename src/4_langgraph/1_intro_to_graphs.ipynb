{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65059f9",
   "metadata": {},
   "source": [
    "Welcome to the Introduction to LangGraph notebook!\n",
    "\n",
    "In this notebook, we'll explore how to use the [LangGraph](https://github.com/langchain-ai/langgraph) Python package to build composable, stateful graphs for LLM workflows. We'll walk through step-by-step examples using tools from LangGraph, LangChain, and Gradio to build an interactive experience. You'll see how graphs can help structure conversational or tool-using flows in AI applications.\n",
    "\n",
    "## What We'll Do\n",
    "\n",
    "- Install and configure the key packages: `langgraph`, `langsmith`, `langchain` (with OpenAI), `langchain-community`, and `pyppeteer`\n",
    "- Set up your environment for running LLM graphs, including configuring credentials for LangSmith and OpenAI\n",
    "- Build and experiment with simple to advanced graph-based workflows\n",
    "\n",
    "## Setup: Install Dependencies\n",
    "\n",
    "Before you begin, make sure you have the required packages installed. You can install them with:\n",
    "\n",
    "```bash\n",
    "uv add langgraph langsmith \"langchain[openai]\" langchain-community pyppeteer\n",
    "```\n",
    "\n",
    "> **Note**: If you haven't already, [sign up for LangSmith](https://smith.langchain.com/) and create a project. You'll also need to update your environment variables with your API keys to run the examples in this notebook.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "import random\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful constants\n",
    "\n",
    "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\", \"Zombies\", \"Rainbows\", \"Eels\", \"Pickles\", \"Muffins\"]\n",
    "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\", \"sparkly\", \"untrustworthy\", \"sarcastic\", \"squishy\", \"haunted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph state\n",
    "# State is the input and output data of the graph\n",
    "# It is a Pydantic model that defines the structure of the state\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph builder\n",
    "# The graph builder is used to build the graph nodes and edges\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add first node. It will be a non-llm node that generates a random response\n",
    "\n",
    "def first_node(state: State) -> State:\n",
    "    reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}\"\n",
    "    messages = [{'role': 'assistant', 'content': reply}]\n",
    "    return State(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges and compile the graph\n",
    "\n",
    "graph_builder.add_node(\"first_node\", first_node)\n",
    "graph_builder.add_edge(START, \"first_node\")\n",
    "graph_builder.add_edge(\"first_node\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the graph\n",
    "state = State(messages=[])\n",
    "graph.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a chatbot node that uses an llm to generate a response\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chatbot_node(state: State) -> State:\n",
    "    response = llm.invoke(state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ed5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges and compile the graph\n",
    "# Display the graph\n",
    "\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_node)\n",
    "graph_builder.add_edge(START, \"chatbot_node\")\n",
    "graph_builder.add_edge(\"chatbot_node\", END)\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5505f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the graph with a query\n",
    "\n",
    "messages = [{'role': 'user', 'content': 'LangGraph vs CrewAI Flows?'}]\n",
    "state = State(messages=messages)\n",
    "graph.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure serper to be used as a tool\n",
    "\n",
    "serper = GoogleSerperAPIWrapper()\n",
    "serper.run(\"LangGraph vs CrewAI Flows?\")\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"search_tool\",\n",
    "    func=serper.run,\n",
    "    description=\"Use this tool to search the web for information\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb482962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tools to LLM\n",
    "# Adding tools to the LLM allows it to use the tools in the graph\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260474fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool node to execute the tools\n",
    "# Binding tools with LLM is different from the tool node.\n",
    "# Binding tools to LLM tells the LLMs about the available tools.\n",
    "# We need to add a tool node to execute the tools.\n",
    "\n",
    "tool_node = ToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the chatbot node to use the llm with tools\n",
    "\n",
    "def chatbot_node(state: State) -> State:\n",
    "    response = llm_with_tools.invoke(state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a144c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes and edges to build graph\n",
    "# Use add_conditional_edges to add edges based on tools_condition\n",
    "# Don't forget to add an edge from tools_node back to chatbot_node\n",
    "\n",
    "graph_builder.add_node(\"chatbot_node\", chatbot_node)\n",
    "graph_builder.add_node(\"tools_node\", tool_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot_node\")\n",
    "graph_builder.add_conditional_edges(\"chatbot_node\", tools_condition, {\"tools\": \"tools_node\", END: END})\n",
    "graph_builder.add_edge(\"tools_node\", \"chatbot_node\")\n",
    "graph_builder.add_edge(\"chatbot_node\", END)\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the graph with a query\n",
    "messages = [{'role': 'user', 'content': 'LangGraph vs CrewAI Flows in 2025?'}]\n",
    "state = State(messages=messages)\n",
    "graph.invoke(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
